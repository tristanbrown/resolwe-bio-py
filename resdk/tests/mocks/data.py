# pylint: disable=bad-continuation,line-too-long,bad-whitespace,missing-docstring
COLLECTIONS_SAMPLE = [
    {u'contributor': 1,
     u'created': u'2016-04-07T08:03:38.314293Z',
     u'data': [13, 14],
     u'description': u'Test colllection',
     u'descriptor': {},
     u'descriptor_schema': None,
     u'id': 21,
     u'modified': u'2016-04-07T08:03:38.314330Z',
     u'name': u'TestCollection',
     u'permissions': {
        u'group': [],
        u'public': [],
        u'user': [u'add', u'download', u'edit', u'share', u'view']},
     u'settings': {},
     u'slug': u'TestCollection'}]

PROCESS_SAMPLE = [
    {u'category': u'upload:',
     u'contributor': 1,
     u'created': u'2016-04-20T10:37:15.058595Z',
     u'description': u'Upload NGS reads in FASTQ format.\n',
     u'id': 99,
     u'input_schema': [
        {u'description': u'NGS reads in FASTQ format. Supported extensions: .fastq.gz (preferred), .fq.* or .fastq.*\n',
         u'label': u'NGS reads (FASTQ)',
         u'name': u'src',
         u'required': True,
         u'type': u'basic:file:',
         u'validate_regex': u'(\\.(fastq|fq)(|\\.gz|\\.bz2|\\.tgz|\\.tar\\.gz|\\.tar\\.bz2|\\.zip|\\.rar|\\.7z))|(\\.bz2)$'}],
         u'modified': u'2016-04-20T10:37:15.058616Z',
         u'name': u'Upload NGS reads',
         u'output_schema': [{u'label': u'Reads file',
   u'name': u'fastq',
   u'type': u'basic:file:'},
  {u'label': u'Number of reads',
   u'name': u'number',
   u'type': u'basic:integer:'},
  {u'label': u'Number of bases', u'name': u'bases', u'type': u'basic:string:'},
  {u'label': u'Quality control with FastQC',
   u'name': u'fastqc_url',
   u'type': u'basic:url:view:'},
  {u'label': u'Download FastQC archive',
   u'name': u'fastqc_archive',
   u'type': u'basic:file:'}],
 u'permissions': {u'group': [], u'public': [], u'user': [u'share', u'view']},
 u'persistence': u'RAW',
 u'run': {u'bash': u're-import "{{ src.file_temp|default:src.file }}" "{{ src.file }}" "fastq|fq|bz2" "fastq" 0.5 "extract"\n\n#detect and if old Illumina encoding is found transform to new format\nfastqFormatDetect.pl ${NAME}.fastq &> encoding.txt\nif [[ $(grep \'Solexa/Illumina1.3+/Illumina1.5+\' "encoding.txt") ]]\nthen\n  sed -i -e \'4~4y/@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghi/!"#$%&\'\\\'\'()*+,-.\\/0123456789:;<=>?@ABCDEFGHIJ/\' "${NAME}.fastq"\nfi\n\ngzip -c ${NAME}.fastq > ${NAME}.fastq.gz\nre-save-file fastq ${NAME}.fastq.gz\n\necho "Postprocessing FastQC..."\nmkdir "fastqc" && fastqc "${NAME}.fastq" --extract --outdir="fastqc" 2> stderr.txt\nre-checkrc "Failed while processing with FastQC."\nif [[ $(grep --text "Failed to process file" stderr.txt) != "" ]]\nthen\n  re-error "Failed while processing with FastQC."\nfi\nre-progress 0.9\n\nBASES=$(awk \'/^Sequence length/ {print $3}\' fastqc/*_fastqc/fastqc_data.txt)\nNUMBER=`sed -ne \'s/^Total Sequences\\s*\\([0-9\\.]\\+\\)\\s*$/\\1/pi\' fastqc/*_fastqc/fastqc_data.txt | head -n 1`\nFASTQC_URL="{\\"name\\":\\"View\\",\\"url\\":\\"fastqc/${NAME}_fastqc/fastqc_report.html\\",\\"refs\\":[\\"fastqc/${NAME}_fastqc\\"]}"\nmv "fastqc/${NAME}_fastqc.zip" .\n\nre-save-file fastqc_archive ${NAME}_fastqc.zip\nre-save number $NUMBER\nre-save bases "\\"$BASES\\""\nre-save fastqc_url $FASTQC_URL\n',
  u'runtime': u'polyglot'},
 u'slug': u'import-upload-reads-fastq',
 u'type': u'data:reads:fastq:single:',
 u'version': 16777233},
 {u'category': u'upload:',
 u'contributor': 1,
 u'created': u'2016-04-20T10:37:15.058595Z',
 u'description': u'Upload NGS reads in FASTQ format.\n',
 u'id': 99,
 u'input_schema': [{u'description': u'NGS reads in FASTQ format. Supported extensions: .fastq.gz (preferred), .fq.* or .fastq.*\n',
   u'label': u'NGS reads (FASTQ)',
   u'name': u'src',
   u'required': True,
   u'type': u'basic:file:',
   u'validate_regex': u'(\\.(fastq|fq)(|\\.gz|\\.bz2|\\.tgz|\\.tar\\.gz|\\.tar\\.bz2|\\.zip|\\.rar|\\.7z))|(\\.bz2)$'}],
 u'modified': u'2016-04-20T10:37:15.058616Z',
 u'name': u'Upload NGS reads',
 u'output_schema': [{u'label': u'Reads file',
   u'name': u'fastq',
   u'type': u'basic:file:'},
  {u'label': u'Number of reads',
   u'name': u'number',
   u'type': u'basic:integer:'},
  {u'label': u'Number of bases', u'name': u'bases', u'type': u'basic:string:'},
  {u'label': u'Quality control with FastQC',
   u'name': u'fastqc_url',
   u'type': u'basic:url:view:'},
  {u'label': u'Download FastQC archive',
   u'name': u'fastqc_archive',
   u'type': u'basic:file:'}],
 u'permissions': {u'group': [], u'public': [], u'user': [u'share', u'view']},
 u'persistence': u'RAW',
 u'run': {u'bash': u're-import "{{ src.file_temp|default:src.file }}" "{{ src.file }}" "fastq|fq|bz2" "fastq" 0.5 "extract"\n\n#detect and if old Illumina encoding is found transform to new format\nfastqFormatDetect.pl ${NAME}.fastq &> encoding.txt\nif [[ $(grep \'Solexa/Illumina1.3+/Illumina1.5+\' "encoding.txt") ]]\nthen\n  sed -i -e \'4~4y/@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghi/!"#$%&\'\\\'\'()*+,-.\\/0123456789:;<=>?@ABCDEFGHIJ/\' "${NAME}.fastq"\nfi\n\ngzip -c ${NAME}.fastq > ${NAME}.fastq.gz\nre-save-file fastq ${NAME}.fastq.gz\n\necho "Postprocessing FastQC..."\nmkdir "fastqc" && fastqc "${NAME}.fastq" --extract --outdir="fastqc" 2> stderr.txt\nre-checkrc "Failed while processing with FastQC."\nif [[ $(grep --text "Failed to process file" stderr.txt) != "" ]]\nthen\n  re-error "Failed while processing with FastQC."\nfi\nre-progress 0.9\n\nBASES=$(awk \'/^Sequence length/ {print $3}\' fastqc/*_fastqc/fastqc_data.txt)\nNUMBER=`sed -ne \'s/^Total Sequences\\s*\\([0-9\\.]\\+\\)\\s*$/\\1/pi\' fastqc/*_fastqc/fastqc_data.txt | head -n 1`\nFASTQC_URL="{\\"name\\":\\"View\\",\\"url\\":\\"fastqc/${NAME}_fastqc/fastqc_report.html\\",\\"refs\\":[\\"fastqc/${NAME}_fastqc\\"]}"\nmv "fastqc/${NAME}_fastqc.zip" .\n\nre-save-file fastqc_archive ${NAME}_fastqc.zip\nre-save number $NUMBER\nre-save bases "\\"$BASES\\""\nre-save fastqc_url $FASTQC_URL\n',
  u'runtime': u'polyglot'},
 u'slug': u'import-upload-reads-fastq',
 u'type': u'data:reads:fastq:single:',
 u'version': 16777234},
 {u'category': u'analyses:variants:',
  u'contributor': 1,
  u'created': u'2016-04-07T07:40:01.593209Z',
  u'description': u'Filtering and annotation of Variant Calling data - Chemical mutagenesis in Dictyostelium discoideum\n',
  u'id': 1,
  u'input_schema': [{u'label': u'Variants file (VCF)',
    u'name': u'variants',
    u'required': True,
    u'type': u'data:variants:vcf:'},
   {u'choices': [{u'label': u'SNV', u'value': u'snv'},
     {u'label': u'INDEL', u'value': u'indel'},
     {u'label': u'SNV_CHR2', u'value': u'snv_chr2'},
     {u'label': u'INDEL_CHR2', u'value': u'indel_chr2'}],
    u'default': u'snv',
    u'description': u'Choice of the analysis type. Use "SNV" or "INDEL" options for the analysis of VCF files prepared by using GATK UnifiedGenotyper -glm option "SNP" or "INDEL", respectively. Choose options SNV_CHR2 or INDEL_CHR2 if duplication of CHR2 was considered as diploidy when running GATK analysis (-ploidy 2 -L chr2:2263132-3015703).\n',
    u'label': u'Analysis type',
    u'name': u'analysis_type',
    u'type': u'basic:string:'},
   {u'label': u'Parental Strain Prefix',
    u'name': u'parental_strain',
    u'placeholder': u'AX4',
    u'type': u'basic:string:'},
   {u'label': u'Mutant Strain Prefix',
    u'name': u'mutant_strain',
    u'placeholder': u'mutant',
    u'type': u'basic:string:'},
   {u'default': 5,
    u'label': u'Read Depth Cutoff',
    u'name': u'read_depth',
    u'type': u'basic:integer:'}],
  u'modified': u'2016-04-07T07:40:01.593226Z',
  u'name': u'Variant filtering (Chemical Mutagenesis)',
  u'output_schema': [{u'description': u'Summarize the input parameters and results.\n',
    u'label': u'Summary',
    u'name': u'summary',
    u'type': u'basic:file:'},
   {u'description': u'A genome VCF file of variants that passed the filters.\n',
    u'label': u'Variants',
    u'name': u'vcf',
    u'type': u'basic:file:'},
   {u'description': u'A data frame of variants that passed the filters.\n',
    u'label': u'Variants filtered',
    u'name': u'variants_filtered',
    u'type': u'basic:file:'},
   {u'description': u'A data frame of variants that contain more than two alternative alleles. These vairants are likely to be false positives.\n',
    u'label': u'Variants filtered (multiple alt. alleles)',
    u'name': u'variants_filtered_alt',
    u'type': u'basic:file:'},
   {u'description': u'Genes that are mutated at least once.\n',
    u'label': u'Gene list (all)',
    u'name': u'gene_list_all',
    u'type': u'basic:file:'},
   {u'description': u'Genes that are mutated at least twice.\n',
    u'label': u'Gene list (top)',
    u'name': u'gene_list_top',
    u'type': u'basic:file:'},
   {u'description': u'List mutations in individual chromosomes.\n',
    u'label': u'Mutations (by chr)',
    u'name': u'mut_chr',
    u'type': u'basic:file:'},
   {u'description': u'List mutations in individual strains.\n',
    u'label': u'Mutations (by strain)',
    u'name': u'mut_strain',
    u'type': u'basic:file:'},
   {u'description': u'List mutants that carry mutations in individual genes.\n',
    u'label': u'Strain (by gene)',
    u'name': u'strain_by_gene',
    u'type': u'basic:file:'}],
  u'permissions': {u'group': [], u'public': [], u'user': [u'share', u'view']},
  u'persistence': u'CAC',
  u'run': {u'bash': u'NAME=`basename \'{{ variants.vcf.file }}\' .vcf`\nre-progress 0.05\n\ncp {{variants.vcf.file}} .\n\nRscript -e \'source("R/{{analysis_type}}.R")\' -e \'{{analysis_type}}(input_file = "\'${NAME}.vcf\'", ref_file = "reference_files/", parental_strain = "{{parental_strain}}", mutant_strain = "{{mutant_strain}}", read_depth = \'{{read_depth}}\')\'\nre-checkrc "VCF file filtering failed"\nre-progress 0.9\n\nif [ -f ${NAME}.vcf_{{read_depth}}/summary.txt ];\nthen\n  re-save-file summary ${NAME}.vcf_{{read_depth}}/summary.txt\nfi\n\nif [ -f ${NAME}.vcf_{{read_depth}}/variants.vcf ];\nthen\n  bgzip -c "${NAME}.vcf_{{read_depth}}/variants.vcf" > "${NAME}.vcf_{{read_depth}}/variants.vcf.bgz"\n  tabix -p vcf "${NAME}.vcf_{{read_depth}}/variants.vcf.bgz"\n  re-save-file vcf ${NAME}.vcf_{{read_depth}}/variants.vcf ${NAME}.vcf_{{read_depth}}/variants.vcf.bgz ${NAME}.vcf_{{read_depth}}/variants.vcf.bgz.tbi\nfi\n\nif [ -f ${NAME}.vcf_{{read_depth}}/variant_filtered.txt ];\nthen\n  re-save-file variants_filtered ${NAME}.vcf_{{read_depth}}/variant_filtered.txt\nfi\n\nif [ -f ${NAME}.vcf_{{read_depth}}/variant_mult_alt.txt ];\nthen\n  re-save-file variants_filtered_alt ${NAME}.vcf_{{read_depth}}/variant_mult_alt.txt\nfi\n\nif [ -f ${NAME}.vcf_{{read_depth}}/gene_list_all.txt ];\nthen\n  re-save-file gene_list_all ${NAME}.vcf_{{read_depth}}/gene_list_all.txt\nfi\n\nif [ -f ${NAME}.vcf_{{read_depth}}/gene_list_top.txt ];\nthen\n  re-save-file gene_list_top ${NAME}.vcf_{{read_depth}}/gene_list_top.txt\nfi\n\nif [ -f ${NAME}.vcf_{{read_depth}}/mutations_by_chr.txt ];\nthen\n  re-save-file mut_chr ${NAME}.vcf_{{read_depth}}/mutations_by_chr.txt\nfi\n\nif [ -f ${NAME}.vcf_{{read_depth}}/mutations_by_strain.txt ];\nthen\n  re-save-file mut_strain ${NAME}.vcf_{{read_depth}}/mutations_by_strain.txt\nfi\n\nif [ -f ${NAME}.vcf_{{read_depth}}/strain_by_gene.txt ];\nthen\n  re-save-file strain_by_gene ${NAME}.vcf_{{read_depth}}/strain_by_gene.txt\nfi\n',
   u'runtime': u'polyglot'},
  u'slug': u'vc_filtering_chem_mutagenesis',
  u'type': u'data:variants:vcf:filtering:',
  u'version': 16777216},
 {u'category': u'analyses:variants:',
  u'contributor': 1,
  u'created': u'2016-04-07T07:40:01.608498Z',
  u'description': u'GATK varint calling. Note: Usage of Genome Analysis Toolkit requires a licence.\n',
  u'id': 2,
  u'input_schema': [{u'label': u'Reference genome',
    u'name': u'genome',
    u'required': True,
    u'type': u'data:genome:fasta:'},
   {u'label': u'Mapped reads',
    u'name': u'mapping',
    u'required': True,
    u'type': u'data:alignment:bam:'},
   {u'default': True,
    u'label': u'Do variant base recalibration and indel realignment',
    u'name': u'br_and_ind_ra',
    u'type': u'basic:boolean:'},
   {u'default': False,
    u'description': u'Writes a file containing metrics about the statistical distribution of insert size (excluding duplicates) and generates a Histogram plot.\n',
    u'label': u'Collect insert size metrics',
    u'name': u'collectinsertsizemetrics',
    u'type': u'basic:boolean:'},
   {u'label': u'Known sites',
    u'name': u'known_sites',
    u'required': False,
    u'type': u'data:variants:vcf:'},
   {u'label': u'Known indels',
    u'name': u'known_indels',
    u'required': False,
    u'type': u'list:data:variants:vcf:'},
   {u'group': [{u'default': u'x',
      u'label': u'Read group identifier',
      u'name': u'ID',
      u'required': True,
      u'type': u'basic:string:'},
     {u'default': u'x',
      u'description': u'Sample. Use pool name where a pool is being sequenced.\n',
      u'label': u'Sample',
      u'name': u'SM',
      u'required': True,
      u'type': u'basic:string:'},
     {u'choices': [{u'label': u'Capillary', u'value': u'Capillary'},
       {u'label': u'Ls454', u'value': u'Ls454'},
       {u'label': u'Illumina', u'value': u'Illumina'},
       {u'label': u'SOLiD', u'value': u'SOLiD'},
       {u'label': u'Helicos', u'value': u'Helicos'},
       {u'label': u'IonTorrent', u'value': u'IonTorrent'},
       {u'label': u'Pacbio', u'value': u'Pacbio'}],
      u'default': u'Illumina',
      u'description': u'Platform/technology used to produce the reads.\n',
      u'label': u'Platform/technology',
      u'name': u'PL',
      u'required': True,
      u'type': u'basic:string:'},
     {u'default': u'x',
      u'label': u'Library',
      u'name': u'LB',
      u'required': True,
      u'type': u'basic:string:'},
     {u'default': u'x',
      u'description': u'Platform unit (e.g. flowcell-barcode.lane for Illumina or slide for SOLiD). Unique identifier.\n',
      u'label': u'Platform unit',
      u'name': u'PU',
      u'required': True,
      u'type': u'basic:string:'},
     {u'default': u'x',
      u'description': u'Name of sequencing center producing the read.\n',
      u'label': u'Sequencing center',
      u'name': u'CN',
      u'required': True,
      u'type': u'basic:string:'},
     {u'description': u'Date the run was produced.\n',
      u'label': u'Date',
      u'name': u'DT',
      u'required': True,
      u'type': u'basic:date:'}],
    u'label': u'Reads information',
    u'name': u'reads_info'},
   {u'group': [{u'default': 10,
      u'description': u'The minimum confidence threshold (phred-scaled) at which the program should emit sites that appear to be possibly variant.\n',
      u'label': u'Emission confidence threshold',
      u'name': u'stand_emit_conf',
      u'required': True,
      u'type': u'basic:integer:'},
     {u'default': 30,
      u'description': u"the minimum confidence threshold (phred-scaled) at which the program should emit variant sites as called. If a site's associated genotype has a confidence score lower than the calling threshold, the program will emit the site as filtered and will annotate it as LowQual. This threshold separates high confidence calls from low confidence calls.\n",
      u'label': u'Calling confidence threshold',
      u'name': u'stand_call_conf',
      u'required': True,
      u'type': u'basic:integer:'}],
    u'label': u'Parameters of HaplotypeCaller',
    u'name': u'Varc_param'}],
  u'modified': u'2016-04-07T07:40:01.608515Z',
  u'name': u'Variant calling (GATK)',
  u'output_schema': [{u'label': u'Called variants file',
    u'name': u'vcf',
    u'type': u'basic:file:'},
   {u'label': u'Insert size metrics',
    u'name': u'ism',
    u'type': u'basic:file:'}],
  u'permissions': {u'group': [], u'public': [], u'user': [u'share', u'view']},
  u'persistence': u'CAC',
  u'run': {u'bash': u'echo "uncompressing genome, indexing"\nGENOME_NAME=`basename \'{{ genome.fasta.file }}\' .fasta.gz`\ngzip -cd {{ genome.fasta.file }} > "${GENOME_NAME}.fasta"\nsamtools faidx "${GENOME_NAME}.fasta"\npicard CreateSequenceDictionary R="${GENOME_NAME}.fasta" O="${GENOME_NAME}.dict"\necho "{\\"proc.progress\\":0.05,\\"proc.rc\\":$?}"\n\necho "bam files processing"\nBAM_FILE=`basename \'{{ mapping.bam.file }}\' .bam`\n\necho "sorting, marking duplicates, indexing"\npicard MarkDuplicates I="{{ mapping.bam.file }}" O="${BAM_FILE}_inds.bam" METRICS_FILE=junk.txt VALIDATION_STRINGENCY=LENIENT\necho "{\\"proc.progress\\":0.1,\\"proc.rc\\":$?}"\npicard AddOrReplaceReadGroups I="${BAM_FILE}_inds.bam" O="${BAM_FILE}_indh.bam" RGID={{reads_info.ID}} RGLB={{reads_info.LB}} RGPL={{reads_info.PL}} RGPU={{reads_info.PU}} RGSM={{reads_info.SM}} RGCN={{reads_info.CN}} RGDT={{reads_info.DT}}\necho "{\\"proc.progress\\":0.15,\\"proc.rc\\":$?}"\nsamtools index "${BAM_FILE}_indh.bam"\necho "{\\"proc.progress\\":0.2,\\"proc.rc\\":$?}"\n\n{% if collectinsertsizemetrics %}\n  picard CollectInsertSizeMetrics I="${BAM_FILE}_indh.bam" O="${BAM_FILE}".CollectInsertSizeMetrics H="${BAM_FILE}".CollectIsertSizeMetrics.pdf VALIDATION_STRINGENCY=LENIENT\n  echo "{\\"proc.progress\\":0.25,\\"proc.rc\\":$?,\\"ism\\":{\\"file\\":\\"${BAM_FILE}.CollectIsertSizeMetrics.pdf\\"}}"\n{% endif %}\n\n{% if br_and_ind_ra %}\n  echo "indel realignment"\n  gatk -T RealignerTargetCreator -I "${BAM_FILE}_indh.bam" -R "${GENOME_NAME}.fasta" -o indel_interval.bed {% if known_indels %} -known {% for indelx in known_indels %}{{ indelx.vcf.file }} {% endfor %}{% endif %}\n  echo "{\\"proc.progress\\":0.3,\\"proc.rc\\":$?}"\n  gatk -T IndelRealigner -I "${BAM_FILE}_indh.bam" -R "${GENOME_NAME}.fasta" -o "${BAM_FILE}_noncal.bam" -targetIntervals indel_interval.bed -compress 0\n  echo "{\\"proc.progress\\":0.35,\\"proc.rc\\":$?}"\n\n  echo "Base recalibration"\n  gatk -T BaseRecalibrator -I "${BAM_FILE}_noncal.bam"  -R "${GENOME_NAME}.fasta" -o recal_data.table -knownSites \'{{ known_sites.vcf.file }}\'\n  echo "{\\"proc.progress\\":0.4,\\"proc.rc\\":$?}"\n  gatk -T PrintReads -I "${BAM_FILE}_noncal.bam" -R "${GENOME_NAME}.fasta" -o "${BAM_FILE}_final.bam" -BQSR recal_data.table\n  echo "{\\"proc.progress\\":0.45,\\"proc.rc\\":$?}"\n{% else %}\n  mv "${BAM_FILE}_indh.bam" "${BAM_FILE}_final.bam"\n{% endif %}\n\nsamtools index "${BAM_FILE}_final.bam"\n\necho "variant calling"\ngatk -T UnifiedGenotyper -I "${BAM_FILE}_final.bam" -R "${GENOME_NAME}.fasta" -o "${BAM_FILE}_GATKvariants.vcf" {% if known_sites %} --dbsnp {{ known_sites.vcf.file }} {% endif %} -stand_call_conf {{ Varc_param.stand_call_conf }} -stand_emit_conf {{ Varc_param.stand_emit_conf }} -rf ReassignOneMappingQuality -RMQF 255 -RMQT 60\necho "{\\"proc.progress\\":0.8,\\"proc.rc\\":$?}"\n\n#echo "hard filtering"\n#gatk -V "${BAM_FILE}_haplotype.vcf" -o "${BAM_FILE}_filtered.vcf" -T VariantFiltration -R "${GENOME_NAME}.fasta" --filterName GATKstandard --filterExpression "QUAL < 30 || QD < 5.0"\n#vcftools --vcf "${BAM_FILE}_filtered.vcr"\n#mv "${BAM_FILE}_filtered.vcr" "${BAM_FILE}_GATKvariants.vcf"\n\nbgzip -c "${BAM_FILE}_GATKvariants.vcf" > "${BAM_FILE}_GATKvariants.vcf.bgz"\necho "{\\"proc.progress\\":0.9,\\"proc.rc\\":$?}"\ntabix -p vcf "${BAM_FILE}_GATKvariants.vcf.bgz"\necho "{\\"proc.progress\\":0.95,\\"proc.rc\\":$?}"\n\necho "{\\"proc.progress\\":1,\\"vcf\\":{\\"file\\": \\"${BAM_FILE}_GATKvariants.vcf\\", \\"refs\\":[\\"${BAM_FILE}_GATKvariants.vcf.bgz\\",\\"${BAM_FILE}_GATKvariants.vcf.bgz.tbi\\"] }}"\n',
   u'runtime': u'polyglot'},
  u'slug': u'vc-gatk',
  u'type': u'data:variants:vcf:gatk:',
  u'version': 16777226},]

DATA_SAMPLE = [
{u'process': 26, u'contributor': 1, u'process_output_schema': [{u'type': u'basic:file:', u'name': u'fastq', u'label': u'Reads file'}, {u'type': u'basic:integer:', u'name': u'number', u'label': u'Number of reads'}, {u'type': u'basic:string:', u'name': u'bases', u'label': u'Number of bases'}, {u'type': u'basic:url:view:', u'name': u'fastqc_url', u'label': u'Quality control with FastQC'}, {u'type': u'basic:file:', u'name': u'fastqc_archive', u'label': u'Download FastQC archive'}], u'id': 13, u'process_type': u'data:reads:fastq:single:', u'process_error': [], u'process_progress': 0, u'input': {u'src': {u'file': u'20151231-shep21-0hr-twist-RZ2638_S4_R1_001.fastq', u'file_temp': u'/home/jure/devel/genialis-base/upload/3b1a12c7-5725-4386-b1c3-98209330cdc6'}}, u'process_info': [], u'status': u'PR', u'process_rc': None, u'started': u'2016-04-18T07:31:03.329782Z', u'process_name': u'Upload NGS reads', u'process_warning': [], u'finished': None, u'slug': u'54861ac8-48fd-4ec9-8dab-07b159442e20', u'permissions': {u'group': [], u'user': [u'download', u'edit', u'share', u'view'], u'public': []}, u'name': u'Name1', u'descriptor_schema': None, u'created': u'2016-04-18T09:31:03.273940Z', u'checksum': None, u'modified': u'2016-04-18T09:31:03.321548Z', u'descriptor': {}, u'process_input_schema': [{u'validate_regex': u'(\\.(fastq|fq)(|\\.gz|\\.bz2|\\.tgz|\\.tar\\.gz|\\.tar\\.bz2|\\.zip|\\.rar|\\.7z))|(\\.bz2)$', u'description': u'NGS reads in FASTQ format. Supported extensions: .fastq.gz (preferred), .fq.* or .fastq.*\n', u'required': True, u'label': u'NGS reads (FASTQ)', u'type': u'basic:file:', u'name': u'src'}], "output": {"fastq": {"file": "example.fastq.gz"},"bases": "75"}},
{u'process': 26, u'contributor': 1, u'process_output_schema': [{u'type': u'basic:file:', u'name': u'fastq', u'label': u'Reads file'}, {u'type': u'basic:integer:', u'name': u'number', u'label': u'Number of reads'}, {u'type': u'basic:string:', u'name': u'bases', u'label': u'Number of bases'}, {u'type': u'basic:url:view:', u'name': u'fastqc_url', u'label': u'Quality control with FastQC'}, {u'type': u'basic:file:', u'name': u'fastqc_archive', u'label': u'Download FastQC archive'}], u'id': 14, u'process_type': u'data:reads:fastq:single:', u'process_error': [], u'process_progress': 100, u'input': {u'src': {u'file': u'20151231-shep21-0hr-twist-RZ2638_S4_R1_001.fastq', u'file_temp': u'/home/jure/devel/genialis-base/upload/bce3fd27-692f-46f6-ba09-bb14c0c7ce9f'}}, u'process_info': [], u'status': u'ER', u'process_rc': 1, u'started': u'2016-04-18T07:31:09.712650Z', u'process_name': u'Upload NGS reads', u'process_warning': [], u'finished': u'2016-04-18T07:31:09.723797Z', u'slug': u'8a3f7685-9942-45d5-9dff-e0c8654ba39b', u'permissions': {u'group': [], u'user': [u'download', u'edit', u'share', u'view'], u'public': []}, u'name': u'Name2', u'descriptor_schema': None, u'created': u'2016-04-18T09:31:09.645791Z', u'checksum': None, u'modified': u'2016-04-18T09:31:09.702595Z', u'descriptor': {}, u'process_input_schema': [{u'validate_regex': u'(\\.(fastq|fq)(|\\.gz|\\.bz2|\\.tgz|\\.tar\\.gz|\\.tar\\.bz2|\\.zip|\\.rar|\\.7z))|(\\.bz2)$', u'description': u'NGS reads in FASTQ format. Supported extensions: .fastq.gz (preferred), .fq.* or .fastq.*\n', u'required': True, u'label': u'NGS reads (FASTQ)', u'type': u'basic:file:', u'name': u'src'}], u'output': {}}
]

